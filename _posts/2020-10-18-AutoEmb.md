---
layout:     post
title:      【论文阅读笔记】AutoEmb
subtitle:   AutoEmb:Automated Embedding Dimensionality Search in Streaming Recommendations
date:       2020-10-18
author:     Siyuan Lou
header-img: img/post-bg-article.jpg
catalog: true
tags:
    - Embedding Search
    - AutoML
typora-root-url: "/Users/swan/Documents/myblog/swan815.github.io"
---

# Title

![image-20201018230443652](/../../../../../../../img/blog/2020-10-18-AutoEmb/image-20201018230443652.png)

# Background

深度学习推荐系统（DLRSs）的结构通常由三层Embedding Layer、Hidden Layer和Output Layer三层组成，在Embedding Layer中对于用户和物品的Embedding维度通常是固定的，但作者在实验中发现，不同用户/物品不同的表示维度是必要的。如下图的实验结果所示：

<img src="/../../../../../../../img/blog/2020-10-18-AutoEmb/image-20201018231503317.png" alt="image-20201018231503317" style="zoom:50%;" />

有如下结论：

+ 随着popularity的增加，推荐模型的表现在不同的Embedding维度都有提高，但是越大的Embedding维度
得到更多收益。
+ 在popularity比较小的时候，Embedding维度比较小就可以得到最优的结果，但是之后会被更大的Embedding维度超越

本文据此提出根据popularity和上下文信息来选择用户和物品的Embedding维度的**AutoEmb**
# Problem Statement
对不同用户/物品选择不同维度存在的两个问题：
+ 因为隐层的第一层维度固定，不同的嵌入层表示维度很难输入进隐层，进行训练。
+ 实际场景中用户/物品数目巨大，手工选择维度不太可能。

# Method(s)
## 1. 不同用户/物品维度的统一问题

作者通过对Embedding变换统一维度输入进Hidden Layer。具体做法可以从下图所示：

<img src="/../../../../../../../img/blog/2020-10-18-AutoEmb/image-20201018231605856.png" alt="image-20201018231605856" style="zoom: 50%;" />

+ Embedding Lookup<img src="/../../../../../../../img/blog/2020-10-18-AutoEmb/image-20201113155638433.png" alt="image-20201113155638433" style="zoom:50%;" />表示将用户$u_i$表示成N个维度空间

+ Linear Transform通过线性变换将维度统一为$d_N$

+ Activation BatchNorm通过BN和激活函数将维度变换为同一数量级，可比较的

+ Hard Selection通过max函数进行维度选择，易知max函数是不可导的

## 2. Controller用于选择Embedding的维度

根据popularity和Embedding维度的关系，设计controller。输入由用户/物品的流行度和上下文信息（之前的参数、当前用户和物品的训练损失）组成，经过中间的隐层，等到每个Embedding表示可能的权值。

<img src="/../../../../../../../img/blog/2020-10-18-AutoEmb/image-20201113162933745.png" alt="image-20201113162933745" style="zoom:50%;" />

最后用户/物品的表示：

<img src="/../../../../../../../img/blog/2020-10-18-AutoEmb/image-20201113163137392.png" alt="image-20201113163137392" style="zoom: 50%;" />

这种加权求和的方式是模型变得端到端可微，可以通过Darts的方法进行优化。

## 3. AutoEmb

一个加入AutoEmb的增强的推荐系统模型结构如图，先经过Controller进行维度选择，将用户和物品的维度选择拼接之后输入之后的三层推荐系统模型。

<img src="/../../../../../../../img/blog/2020-10-18-AutoEmb/image-20201113164805619.png" alt="image-20201113164805619" style="zoom:50%;" />

这里的模型参数自然就包括了两部分，包括了三层深度学习推荐系统的模型参数$W$和Controller的参数$\theta$，这里使用基于DARTS的方法进行联合训练和优化$\theta$。

使用梯度下降的方法，用training loss $𝐿_{𝑡𝑟𝑎𝑖𝑛} \rightarrow W$，validation loss$ 𝐿_{𝑣𝑎𝑙} \rightarrow \theta$，training loss和validation loss同时有DLRSs的参数$𝑊$和Controller的参数$\theta$决定。

<img src="/../../../../../../../img/blog/2020-10-18-AutoEmb/image-20201113165836433.png" alt="image-20201113165836433" style="zoom:50%;" />

+ Embedding维度搜索目标是找到最优的$θ^∗$ 通过最小化"validation loss"
+ DLRS的目标是训练找到$W^∗$
+ Bilevel optimization problem:广义上来说，双层规划就是下层函数的解是上层函数的计算参数，在这里
+ Lower level variable : W upper-level variable:θ

AutoEmb的基于DARTS的优化方法：

<img src="/../../../../../../../img/blog/2020-10-18-AutoEmb/image-20201113170418914.png" alt="image-20201113170418914" style="zoom:50%;" />

# Evaluation

论文实验中使用的数据集：

<img src="/../../../../../../../img/blog/2020-10-18-AutoEmb/image-20201113170543919.png" alt="image-20201113170543919" style="zoom:50%;" />

实验结果对比：

<img src="/../../../../../../../img/blog/2020-10-18-AutoEmb/image-20201113170610485.png" alt="image-20201113170610485" style="zoom:50%;" />

其中，FSE表示Fixed-size Embedding固定Embedding维度，在实验中Embedding的维度是所有维度求和；SAM表示Superivised Attention Model，和AutoEmb结构一样，但是对$W$和$θ$同时更新，通过端到端方式；DARTS是使用原始DARTS在N=3的时候训练得到一组实值。


# Notes

# References
[论文链接]: https://arxiv.org/abs/2002.11252
[可微分搜索（DARTS）]: https://blog.csdn.net/u012347027/article/details/106175020
[DARTS 公式推导]: https://zhuanlan.zhihu.com/p/73037439

